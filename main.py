#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Raspberry Pi Engelli Destek Sistemi
GerÃ§ek zamanlÄ± nesne algÄ±lama ve sesli uyarÄ± sistemi

Gereksinimler:
- OpenCV
- YOLOv8 (ultralytics)
- pyttsx3
- numpy
"""

import cv2
import numpy as np
import time
import threading
from typing import Tuple, List, Dict, Optional

# ModÃ¼l importlarÄ±
from object_detector import ObjectDetector
from distance_checker import DistanceChecker
from voice_alert import VoiceAlert
from navigation_guide import NavigationGuide
from config import Config


class DisabilityAssistanceSystem:
    """
    Engelli destek sistemi ana sÄ±nÄ±fÄ±
    Kamera gÃ¶rÃ¼ntÃ¼sÃ¼nden nesne algÄ±lama ve sesli uyarÄ± saÄŸlar
    """
    
    def __init__(self):
        """Sistem bileÅŸenlerini baÅŸlat"""
        print("ğŸš€ Engelli Destek Sistemi baÅŸlatÄ±lÄ±yor...")
        
        # KonfigÃ¼rasyon yÃ¼kle
        self.config = Config()
        
        # Kamera baÅŸlat
        self.cap = None
        self.initialize_camera()
        
        # Sistem bileÅŸenlerini baÅŸlat
        self.detector = ObjectDetector(self.config)
        self.distance_checker = DistanceChecker(self.config)
        self.voice_alert = VoiceAlert(self.config)
        self.navigation_guide = NavigationGuide(self.config)
        
        # Sistem durumu
        self.running = False
        self.frame_count = 0
        self.fps_counter = 0
        self.last_fps_time = time.time()
        
        print("âœ… Sistem baÅŸarÄ±yla baÅŸlatÄ±ldÄ±!")
    
    def initialize_camera(self) -> bool:
        """
        KamerayÄ± baÅŸlat ve ayarlarÄ±nÄ± yap
        
        Returns:
            bool: Kamera baÅŸlatma durumu
        """
        try:
            # KamerayÄ± aÃ§ (genellikle 0, USB kamera varsa 1 olabilir)
            self.cap = cv2.VideoCapture(0)
            
            if not self.cap.isOpened():
                print("âŒ Kamera aÃ§Ä±lamadÄ±!")
                return False
            
            # Kamera ayarlarÄ± (Raspberry Pi iÃ§in optimize edilmiÅŸ)
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.config.CAMERA_WIDTH)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.config.CAMERA_HEIGHT)
            self.cap.set(cv2.CAP_PROP_FPS, self.config.CAMERA_FPS)
            
            # Buffer size'Ä± azalt (gecikmeyi Ã¶nlemek iÃ§in)
            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            
            print(f"ğŸ“¹ Kamera baÅŸlatÄ±ldÄ±: {self.config.CAMERA_WIDTH}x{self.config.CAMERA_HEIGHT} @ {self.config.CAMERA_FPS}fps")
            return True
            
        except Exception as e:
            print(f"âŒ Kamera baÅŸlatma hatasÄ±: {e}")
            return False
    
    def read_frame(self) -> Optional[np.ndarray]:
        """
        Kameradan frame oku
        
        Returns:
            Optional[np.ndarray]: Okunan frame veya None
        """
        if not self.cap or not self.cap.isOpened():
            return None
        
        ret, frame = self.cap.read()
        if not ret:
            print("âš ï¸ Frame okunamadÄ±!")
            return None
        
        return frame
    
    def calculate_fps(self) -> float:
        """
        FPS hesapla (performans takibi iÃ§in)
        
        Returns:
            float: Mevcut FPS deÄŸeri
        """
        self.frame_count += 1
        current_time = time.time()
        
        if current_time - self.last_fps_time >= 1.0:
            self.fps_counter = self.frame_count / (current_time - self.last_fps_time)
            self.frame_count = 0
            self.last_fps_time = current_time
        
        return self.fps_counter
    
    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:
        """
        Frame'i iÅŸle: nesne algÄ±lama ve analiz
        
        Args:
            frame: Ä°ÅŸlenecek gÃ¶rÃ¼ntÃ¼ frame'i
            
        Returns:
            Tuple[np.ndarray, List[Dict]]: Ä°ÅŸlenmiÅŸ frame ve algÄ±lanan nesneler
        """
        # Nesne algÄ±lama yap
        detections = self.detector.detect_objects(frame)
        
        # Debug iÃ§in bounding box'larÄ± Ã§iz
        annotated_frame = self.detector.draw_detections(frame.copy(), detections)
        
        # Mesafe kontrolÃ¼ yap
        close_objects = self.distance_checker.check_distances(detections, frame.shape)
        
        # Navigasyon analizi yap
        navigation_info = self.navigation_guide.analyze_regions(detections, frame.shape)
        
        return annotated_frame, detections, close_objects, navigation_info
    
    def handle_alerts(self, detections: List[Dict], close_objects: List[Dict], 
                     navigation_info: Dict):
        """
        Sesli uyarÄ±larÄ± ve yÃ¶nlendirmeleri iÅŸle
        
        Args:
            detections: AlgÄ±lanan nesneler
            close_objects: YakÄ±n nesneler
            navigation_info: Navigasyon bilgileri
        """
        # YakÄ±n nesne uyarÄ±larÄ±
        for obj in close_objects:
            self.voice_alert.alert_close_object(obj)
        
        # Navigasyon yÃ¶nlendirmeleri
        if navigation_info['center_blocked']:
            direction = navigation_info['recommended_direction']
            if direction:
                self.voice_alert.give_direction(direction)
        
        # Genel nesne bildirimleri (throttled)
        self.voice_alert.announce_objects(detections)
    
    def display_info(self, frame: np.ndarray, detections: List[Dict], 
                    navigation_info: Dict) -> np.ndarray:
        """
        Frame Ã¼zerine bilgi metinlerini ekle
        
        Args:
            frame: GÃ¶rÃ¼ntÃ¼ frame'i
            detections: AlgÄ±lanan nesneler
            navigation_info: Navigasyon bilgileri
            
        Returns:
            np.ndarray: Bilgi eklenmiÅŸ frame
        """
        # FPS gÃ¶ster
        fps = self.calculate_fps()
        cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # AlgÄ±lanan nesne sayÄ±sÄ±nÄ± gÃ¶ster
        cv2.putText(frame, f"Nesneler: {len(detections)}", (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # Navigasyon durumunu gÃ¶ster
        if navigation_info['center_blocked']:
            direction = navigation_info['recommended_direction']
            if direction:
                cv2.putText(frame, f"YÃ¶n: {direction}", (10, 90),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        # BÃ¶lge Ã§izgileri (debug iÃ§in)
        height, width = frame.shape[:2]
        left_line = width // 3
        right_line = 2 * width // 3
        
        cv2.line(frame, (left_line, 0), (left_line, height), (255, 255, 0), 2)
        cv2.line(frame, (right_line, 0), (right_line, height), (255, 255, 0), 2)
        
        return frame
    
    def run(self):
        """Ana sistem dÃ¶ngÃ¼sÃ¼"""
        print("ğŸ¯ Sistem Ã§alÄ±ÅŸmaya baÅŸladÄ±. Ã‡Ä±kmak iÃ§in 'q' tuÅŸuna basÄ±n.")
        self.running = True
        
        try:
            while self.running:
                # Frame oku
                frame = self.read_frame()
                if frame is None:
                    print("âš ï¸ Frame alÄ±namadÄ±, yeniden denenecek...")
                    time.sleep(0.1)
                    continue
                
                # Frame'i iÅŸle
                annotated_frame, detections, close_objects, navigation_info = self.process_frame(frame)
                
                # UyarÄ±larÄ± iÅŸle (ayrÄ± thread'de Ã§alÄ±ÅŸabilir)
                if len(detections) > 0 or len(close_objects) > 0:
                    # Sesli uyarÄ±larÄ± non-blocking ÅŸekilde Ã§al
                    threading.Thread(
                        target=self.handle_alerts,
                        args=(detections, close_objects, navigation_info),
                        daemon=True
                    ).start()
                
                # Bilgileri ekle
                display_frame = self.display_info(annotated_frame, detections, navigation_info)
                
                # GÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¶ster (debug iÃ§in)
                if self.config.SHOW_DISPLAY:
                    cv2.imshow('Engelli Destek Sistemi', display_frame)
                
                # Ã‡Ä±kÄ±ÅŸ kontrolÃ¼
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("ğŸ›‘ Ã‡Ä±kÄ±ÅŸ yapÄ±lÄ±yor...")
                    break
                elif key == ord('s'):
                    # Ses ayarlarÄ±nÄ± deÄŸiÅŸtir
                    self.voice_alert.toggle_sound()
                elif key == ord('d'):
                    # Debug modunu aÃ§/kapat
                    self.config.DEBUG_MODE = not self.config.DEBUG_MODE
                    print(f"Debug modu: {'AÃ‡IK' if self.config.DEBUG_MODE else 'KAPALI'}")
                
                # CPU'yu rahatlatmak iÃ§in kÄ±sa bekleme
                time.sleep(0.01)
        
        except KeyboardInterrupt:
            print("\nğŸ›‘ Klavye ile durduruldu.")
        
        except Exception as e:
            print(f"âŒ Sistem hatasÄ±: {e}")
        
        finally:
            self.cleanup()
    
    def cleanup(self):
        """Sistem kaynaklarÄ±nÄ± temizle"""
        print("ğŸ§¹ Sistem kapatÄ±lÄ±yor...")
        
        self.running = False
        
        # KamerayÄ± kapat
        if self.cap:
            self.cap.release()
        
        # OpenCV pencerelerini kapat
        cv2.destroyAllWindows()
        
        # Sesli uyarÄ± sistemini kapat
        if hasattr(self, 'voice_alert'):
            self.voice_alert.cleanup()
        
        print("âœ… Sistem baÅŸarÄ±yla kapatÄ±ldÄ±.")


def main():
    """Ana fonksiyon"""
    try:
        # Sistem oluÅŸtur ve Ã§alÄ±ÅŸtÄ±r
        system = DisabilityAssistanceSystem()
        system.run()
        
    except Exception as e:
        print(f"âŒ Sistem baÅŸlatma hatasÄ±: {e}")
        print("ğŸ”§ LÃ¼tfen kamera baÄŸlantÄ±sÄ±nÄ± ve gerekli kÃ¼tÃ¼phaneleri kontrol edin.")


if __name__ == "__main__":
    main()
